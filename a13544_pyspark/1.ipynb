{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tweets from air_transit_2007.csv\n"
     ]
    }
   ],
   "source": [
    "# # Init pyspark\n",
    "# from pyspark import SparkContext\n",
    "# sc = SparkContext.getOrCreate()\n",
    "# # Init sparksql -- Only used to format the output nicely!\n",
    "# from pyspark.sql import SQLContext\n",
    "# sqlContext = SQLContext(sc)\n",
    "\n",
    "# rows = sc.textFile(\"/air_transit_2007.csv\")\n",
    "# #rows = sc.textFile(\"/Users/abel/Downloads/spare_time/working/a13544_600_spark/air_transit_2007.csv\")\n",
    "\n",
    "# data = rows.map(lambda line: line.split(\",\"))\n",
    "# # data.cache()\n",
    "\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "# A simple demo for working with SparkSQL and Tweets\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import HiveContext, Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "import json\n",
    "import sys\n",
    "\n",
    "\n",
    "inputFile = 'air_transit_2007.csv'\n",
    "#inputFile = '/Users/abel/Downloads/spare_time/working/a13544_600_spark/air_transit_2007.csv'\n",
    "\n",
    "conf = SparkConf().setAppName(\"SparkSQLAirTransit\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "hiveCtx = HiveContext(sc)\n",
    "print(\"Loading tweets from \" + inputFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- DayofMonth: integer (nullable = true)\n",
      " |-- DayOfWeek: integer (nullable = true)\n",
      " |-- DepTime: string (nullable = true)\n",
      " |-- CRSDepTime: integer (nullable = true)\n",
      " |-- ArrTime: string (nullable = true)\n",
      " |-- CRSArrTime: integer (nullable = true)\n",
      " |-- UniqueCarrier: string (nullable = true)\n",
      " |-- FlightNum: integer (nullable = true)\n",
      " |-- TailNum: string (nullable = true)\n",
      " |-- ActualElapsedTime: string (nullable = true)\n",
      " |-- CRSElapsedTime: integer (nullable = true)\n",
      " |-- AirTime: string (nullable = true)\n",
      " |-- ArrDelay: string (nullable = true)\n",
      " |-- DepDelay: string (nullable = true)\n",
      " |-- Origin: string (nullable = true)\n",
      " |-- Dest: string (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- TaxiIn: integer (nullable = true)\n",
      " |-- TaxiOut: integer (nullable = true)\n",
      " |-- Cancelled: integer (nullable = true)\n",
      " |-- CancellationCode: string (nullable = true)\n",
      " |-- Diverted: integer (nullable = true)\n",
      " |-- CarrierDelay: integer (nullable = true)\n",
      " |-- WeatherDelay: integer (nullable = true)\n",
      " |-- NASDelay: integer (nullable = true)\n",
      " |-- SecurityDelay: integer (nullable = true)\n",
      " |-- LateAircraftDelay: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = hiveCtx.read.option(\"header\",True).csv(inputFile,inferSchema =True)\n",
    "input.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myair_transits:\n",
      "Row(Year=2007, Month=1, DayofMonth=1, DayOfWeek=1, DepTime='1232', CRSDepTime=1225, ArrTime='1341', CRSArrTime=1340, UniqueCarrier='WN', FlightNum=2891, TailNum='N351', ActualElapsedTime='69', CRSElapsedTime=75, AirTime='54', ArrDelay='1', DepDelay='7', Origin='SMF', Dest='ONT', Distance=389, TaxiIn=4, TaxiOut=11, Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0) \n",
      "\n",
      "Row(Year=2007, Month=1, DayofMonth=1, DayOfWeek=1, DepTime='1918', CRSDepTime=1905, ArrTime='2043', CRSArrTime=2035, UniqueCarrier='WN', FlightNum=462, TailNum='N370', ActualElapsedTime='85', CRSElapsedTime=90, AirTime='74', ArrDelay='8', DepDelay='13', Origin='SMF', Dest='PDX', Distance=479, TaxiIn=5, TaxiOut=6, Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay=0, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=0) \n",
      "\n",
      "Row(Year=2007, Month=1, DayofMonth=1, DayOfWeek=1, DepTime='2206', CRSDepTime=2130, ArrTime='2334', CRSArrTime=2300, UniqueCarrier='WN', FlightNum=1229, TailNum='N685', ActualElapsedTime='88', CRSElapsedTime=90, AirTime='73', ArrDelay='34', DepDelay='36', Origin='SMF', Dest='PDX', Distance=479, TaxiIn=6, TaxiOut=9, Cancelled=0, CancellationCode=None, Diverted=0, CarrierDelay=3, WeatherDelay=0, NASDelay=0, SecurityDelay=0, LateAircraftDelay=31) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input.registerTempTable(\"air_transit\")\n",
    "\n",
    "myair_transits = hiveCtx.sql(\"SELECT * FROM air_transit  LIMIT 3\")\n",
    "print('myair_transits:' )\n",
    "for item in myair_transits.collect():\n",
    "    print(item, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1\n",
    "Compute the total number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mycount= 756\n"
     ]
    }
   ],
   "source": [
    "# Response...\n",
    "mycount = hiveCtx.sql(\"SELECT count(*) as mycount FROM air_transit\")\n",
    "print('mycount=', mycount.collect()[0]['mycount'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of operated flights per month:\n",
      "1 month 100\n",
      "2 month 249\n",
      "12 month 407\n"
     ]
    }
   ],
   "source": [
    "## Q2\n",
    "#Find total number of operated flights per month, sorted by the month..\n",
    "\n",
    "\n",
    "mymonth = hiveCtx.sql(\"select Month, count(*) as flight_number from air_transit group by Month order by Month LIMIT 100\")\n",
    "print('total number of operated flights per month:')  \n",
    "for item in mymonth.collect():\n",
    "    print(item['Month'], 'month', item['flight_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest_number_filghts:  N6700\n"
     ]
    }
   ],
   "source": [
    "## Q3\n",
    "# Find the plane with the highest number of flights. Each plane has a unique TailNum\n",
    "highest_number_filghts = hiveCtx.sql(\"SELECT TailNum, SUM (FlightNum) FROM air_transit GROUP BY TailNum LIMIT 100\")\n",
    "print('highest_number_filghts: ', highest_number_filghts.collect()[0]['TailNum'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- We make  ----------\n",
      "total flight time of each airplane: \n",
      "N3767  total fight time is 907.0\n",
      "N385DN  total fight time is 804.0\n",
      "N6707A  total fight time is 743.0\n",
      "N3731T  total fight time is 696.0\n",
      "N904DE  total fight time is 696.0\n",
      "N377DA  total fight time is 685.0\n",
      "N391DA  total fight time is 681.0\n",
      "N830MH  total fight time is 661.0\n",
      "N925DL  total fight time is 640.0\n",
      "N948DL  total fight time is 627.0\n",
      "N946DL  total fight time is 595.0\n",
      "N645DL  total fight time is 577.0\n",
      "N912DL  total fight time is 563.0\n",
      "N394DA  total fight time is 553.0\n",
      "N6709  total fight time is 548.0\n",
      "N718SW  total fight time is 544.0\n",
      "N135DL  total fight time is 521.0\n",
      "N980DL  total fight time is 485.0\n",
      "N6702  total fight time is 482.0\n",
      "N995DL  total fight time is 478.0\n",
      "N911DL  total fight time is 477.0\n",
      "N3766  total fight time is 473.0\n",
      "N372DA  total fight time is 449.0\n",
      "N655DL  total fight time is 443.0\n",
      "N988DL  total fight time is 430.0\n",
      "N931DL  total fight time is 423.0\n",
      "N828MH  total fight time is 414.0\n",
      "N654DL  total fight time is 413.0\n",
      "N399DA  total fight time is 376.0\n",
      "N916DE  total fight time is 372.0\n",
      "N3742C  total fight time is 360.0\n",
      "N994DL  total fight time is 358.0\n",
      "N909DE  total fight time is 357.0\n",
      "N959DL  total fight time is 346.0\n",
      "N908DE  total fight time is 346.0\n",
      "N926DL  total fight time is 345.0\n",
      "N919DE  total fight time is 345.0\n",
      "N829MH  total fight time is 344.0\n",
      "N3760C  total fight time is 341.0\n",
      "N913DN  total fight time is 340.0\n",
      "N386DA  total fight time is 330.0\n",
      "N788SA  total fight time is 328.0\n",
      "N924DL  total fight time is 328.0\n",
      "N6703D  total fight time is 323.0\n",
      "N696DA  total fight time is 322.0\n",
      "N1402A  total fight time is 316.0\n",
      "N915DE  total fight time is 316.0\n",
      "N665DN  total fight time is 315.0\n",
      "N413WN  total fight time is 311.0\n",
      "N922DL  total fight time is 305.0\n",
      "N398DA  total fight time is 301.0\n",
      "N999DN  total fight time is 300.0\n",
      "N644DL  total fight time is 300.0\n",
      "N3763D  total fight time is 299.0\n",
      "N911DE  total fight time is 296.0\n",
      "N908DL  total fight time is 296.0\n",
      "N374SW  total fight time is 294.0\n",
      "N6700  total fight time is 291.0\n",
      "N900DE  total fight time is 289.0\n",
      "N627DL  total fight time is 285.0\n",
      "N371DA  total fight time is 283.0\n",
      "N694DA  total fight time is 281.0\n",
      "N974DL  total fight time is 281.0\n",
      "N616DL  total fight time is 277.0\n",
      "N910DE  total fight time is 276.0\n",
      "N229WN  total fight time is 275.0\n",
      "N953DL  total fight time is 274.0\n",
      "N136DL  total fight time is 274.0\n",
      "N680DA  total fight time is 273.0\n",
      "N752SW  total fight time is 272.0\n",
      "N204  total fight time is 270.0\n",
      "N774  total fight time is 270.0\n",
      "N6711M  total fight time is 269.0\n",
      "N790SW  total fight time is 268.0\n",
      "N912DE  total fight time is 268.0\n",
      "N6701  total fight time is 267.0\n",
      "N918DE  total fight time is 266.0\n",
      "N737JW  total fight time is 266.0\n",
      "N907DL  total fight time is 263.0\n",
      "N968DL  total fight time is 262.0\n",
      "N456WN  total fight time is 262.0\n",
      "N635SW  total fight time is 260.0\n",
      "N426WN  total fight time is 259.0\n",
      "N666DN  total fight time is 257.0\n",
      "N687DL  total fight time is 257.0\n",
      "N611SW  total fight time is 257.0\n",
      "N903DA  total fight time is 254.0\n",
      "N799SW  total fight time is 253.0\n",
      "N460WN  total fight time is 253.0\n",
      "N904DL  total fight time is 248.0\n",
      "N397DA  total fight time is 242.0\n",
      "N663DN  total fight time is 240.0\n",
      "N381DA  total fight time is 240.0\n",
      "N912DN  total fight time is 239.0\n",
      "N914DE  total fight time is 237.0\n",
      "N744SW  total fight time is 234.0\n",
      "N623DL  total fight time is 233.0\n",
      "N309SW  total fight time is 233.0\n",
      "N233LV  total fight time is 232.0\n",
      "N628DL  total fight time is 232.0\n"
     ]
    }
   ],
   "source": [
    "## Q4\n",
    "# Compute the total flight time of each airplane, sorted by flight time in descending order.\n",
    "total_flight_times = hiveCtx.sql(\"SELECT TailNum, SUM (AirTime) as total_fight_time FROM air_transit GROUP BY TailNum order by total_fight_time desc LIMIT 100\")\n",
    "print('-'*10, 'We make ', '-'*10)\n",
    "print('total flight time of each airplane: ')\n",
    "for item in  total_flight_times.collect():\n",
    "    print(item['TailNum'], ' total fight time is', item['total_fight_time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ----------\n",
      "{'SNA': 43, 'SMF': 43, 'STL': 28}\n",
      "2 ----------\n",
      "{'LAS': 161, 'LAX': 102}\n",
      "3 ----------\n",
      "{}\n",
      "4 ----------\n",
      "{}\n",
      "5 ----------\n",
      "{}\n",
      "6 ----------\n",
      "{}\n",
      "7 ----------\n",
      "{}\n",
      "8 ----------\n",
      "{}\n",
      "9 ----------\n",
      "{}\n",
      "10 ----------\n",
      "{}\n",
      "11 ----------\n",
      "{}\n",
      "12 ----------\n",
      "{'MSY': 10, 'GEG': 2, 'SNA': 8, 'DCA': 32, 'ORF': 2, 'SAV': 4, 'CMH': 1, 'PNS': 3, 'IAH': 3, 'HNL': 3, 'CVG': 32, 'LGA': 88, 'AUS': 1, 'SJU': 1, 'SRQ': 3, 'CHS': 6, 'RSW': 7, 'BOS': 57, 'EWR': 4, 'LAS': 10, 'DEN': 5, 'IAD': 1, 'BOI': 3, 'SEA': 5, 'MCI': 3, 'CLT': 8, 'PBI': 13, 'ABQ': 3, 'SDF': 2, 'BDL': 4, 'PDX': 1, 'MIA': 5, 'TPA': 27, 'BWI': 4, 'SMF': 2, 'PHX': 5, 'STL': 2, 'DFW': 5, 'GSP': 2, 'SFO': 11, 'MEM': 2, 'BHM': 5, 'ATL': 197, 'FLL': 22, 'RIC': 3, 'VPS': 2, 'LIT': 1, 'ORD': 5, 'RDU': 6, 'MKE': 2, 'HSV': 2, 'PIT': 5, 'IND': 3, 'TYS': 2, 'ONT': 3, 'JAX': 6, 'LAX': 24, 'MCO': 39, 'ROC': 2, 'SAN': 4, 'JFK': 19, 'DAB': 1, 'PHL': 7, 'SAT': 5, 'SLC': 50}\n"
     ]
    }
   ],
   "source": [
    "# q5 Find the busiest airport (in terms of number of departures + arrivals of all operated flights) for each month.\n",
    "from pyspark.sql.functions import col\n",
    "import operator\n",
    "df = input\n",
    "\n",
    "for month in range(1, 12+1):\n",
    "    print(month, '-'*10)\n",
    "    df1=df.filter(col('Month').isin([month])).groupBy('Origin').count()\n",
    "    df2=df.filter(col('Month').isin([month])).groupBy('Dest').count()\n",
    "    #print(type(df1), type(df2))\n",
    "    k_v = {}\n",
    "    for orgin in df1.collect():\n",
    "#         print(orgin['Origin'],orgin['count'])\n",
    "        k_v[orgin['Origin']] = orgin['count']\n",
    "    for dest in df2.collect():\n",
    "        if k_v.get(dest['Dest']) :\n",
    "#             print(dest)\n",
    "#             print('before',k_v[dest['Dest']])\n",
    "            k_v[dest['Dest']] += dest['count']\n",
    "#             print('after',k_v[dest['Dest']])\n",
    "\n",
    "    print(k_v)\n",
    "    if k_v is None:\n",
    "        month_max = max(k_v.items(), key=operator.itemgetter(1))[0]\n",
    "        print('month_max:', month_max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 all of group:\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "|FlightNum|avg(CarrierDelay)|avg(WeatherDelay)|avg(NASDelay)|avg(SecurityDelay)|avg(LateAircraftDelay)|\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "|     1959|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     2659|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1238|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1591|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1645|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1460|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1522|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|      243|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1721|              0.0|              0.0|         33.0|               0.0|                   0.0|\n",
      "|     1896|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|      516|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1618|              2.5|              0.0|          0.0|               0.0|                  42.0|\n",
      "|     1650|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1699|             78.0|              0.0|          0.0|               0.0|                  50.0|\n",
      "|       31|              5.0|              0.0|          8.0|               0.0|                   7.0|\n",
      "|     1975|             20.0|              0.0|          7.0|               0.0|                   9.0|\n",
      "|     1265|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1884|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|     1977|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "|      898|              0.0|              0.0|          0.0|               0.0|                   0.0|\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "2 the filghtnum is: 1728\n",
      "3 the max row:\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "|FlightNum|avg(CarrierDelay)|avg(WeatherDelay)|avg(NASDelay)|avg(SecurityDelay)|avg(LateAircraftDelay)|\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "|     1728|              0.0|              0.0|        123.0|               0.0|                   0.0|\n",
      "+---------+-----------------+-----------------+-------------+------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Q6\n",
    "# 6nd the airline with highest average delay of each type in March 2007. \n",
    "#Note: do not write separate code for each error type. \n",
    "# You should compute a single RDD where each row contains the delay type, \n",
    "# the airline that is worst regarding that delay type, and its average delay of that type in minutes.\n",
    "\n",
    "import pyspark.sql.functions as F \n",
    "from pyspark.sql.functions import count, avg\n",
    "from pyspark.sql.functions import  max as max_\n",
    "\n",
    "# d_columns =  ['CarrierDelay','WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "print('1 all of group:')\n",
    "df1 = df.groupBy(\"FlightNum\") \\\n",
    "    .avg('CarrierDelay','WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay')\n",
    "df1.show()\n",
    "\n",
    "r = df1.groupBy(\"FlightNum\").agg(F.sum(df1[1]+df1[2] + df1[3] + df1[4]).alias('result')).orderBy('result',ascending=False).head(1)\n",
    "print('2 the filghtnum is:', r[0].FlightNum)\n",
    "\n",
    "print('3 the max row:')\n",
    "df1.filter(col('FlightNum').isin([r[0].FlightNum])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter out week 3\n",
      "+--------------+-------+--------+--------+\n",
      "|CRSElapsedTime|AirTime|ArrDelay|DepDelay|\n",
      "+--------------+-------+--------+--------+\n",
      "+--------------+-------+--------+--------+\n",
      "\n",
      "median of [12:16]:\n",
      "[]\n",
      "mean of [19:21] :\n",
      "+------+-------+\n",
      "|TaxiIn|TaxiOut|\n",
      "+------+-------+\n",
      "|  null|   null|\n",
      "+------+-------+\n",
      "\n",
      "mode of [25:29] :\n"
     ]
    }
   ],
   "source": [
    "## q7\n",
    "# Compute median, mean, and mode of columns 12-16, 19-21 and 25-29 \n",
    "# for the flights in the third week of 2007. Exclude the non-numeric values.\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "print('filter out week 3')\n",
    "mydf = df.filter(col('DayOfWeek').isin([3])) \n",
    "\n",
    "\n",
    "df1 = mydf.select(mydf.columns[12:16])\n",
    "df1.show()\n",
    "# res  = df1.select(*[F.percentile_approx(c).alias(c) for c in df1.columns])\n",
    "# res.show()\n",
    "# for name in ('CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay'):\n",
    "\n",
    "quantiles = df1.approxQuantile(\"CRSElapsedTime\", [0.25, 0.5, 0.75], 0)\n",
    "print('median of [12:16]:')\n",
    "print(quantiles)\n",
    "\n",
    "df2 = mydf.select(mydf.columns[19:21])\n",
    "# df2.show()\n",
    "res2  = df2.select(*[F.mean(c).alias(c) for c in df2.columns])\n",
    "print('mean of [19:21] :')\n",
    "res2.show()\n",
    "\n",
    "df3 = mydf.select(mydf.columns[25:29])\n",
    "# df3.show()\n",
    "print('mode of [25:29] :')\n",
    "# [df3.groupby(i).count().orderBy(\"count\", ascending=False).first()[0] for i in df3.columns]\n",
    "for i in df3.columns:\n",
    "    t = df3.groupby(i).count().orderBy(\"count\", ascending=False).first()\n",
    "    if t is not None:\n",
    "        print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "|2007|    2|         1|        4|   1337|      1335|   2114|      2135|           WN|      110| N456WN|              277|           300|    262|     -21|       2|   LAX| PHL|    2401|     8|      7|        0|            null|       0|           0|           0|       0|            0|                0|\n",
      "|2007|    2|         1|        4|     NA|       700|     NA|      1500|           WN|     1280|      0|               NA|           300|     NA|      NA|      NA|   LAX| PHL|    2401|     0|      0|        1|               A|       0|           0|           0|       0|            0|                0|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+\n",
      "\n",
      "stay 3:0 hour, it means before we shoulf flight here at least before back-fight start time - 3hours\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n",
      "|Year|Month|DayofMonth|DayOfWeek|DepTime|CRSDepTime|ArrTime|CRSArrTime|UniqueCarrier|FlightNum|TailNum|ActualElapsedTime|CRSElapsedTime|AirTime|ArrDelay|DepDelay|Origin|Dest|Distance|TaxiIn|TaxiOut|Cancelled|CancellationCode|Diverted|CarrierDelay|WeatherDelay|NASDelay|SecurityDelay|LateAircraftDelay|DepTime_Date|ArrTime_Date|\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n",
      "+----+-----+----------+---------+-------+----------+-------+----------+-------------+---------+-------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+------------+------------+--------+-------------+-----------------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Q8\n",
    "#Assume that a passenger wants to travel from Philadelphia International Airport (airport code: PHL) \n",
    "# to Los Angeles International Airport (airport code: LAX), and then go back to Philadelphia (PHL). \n",
    "# He departs PHL not earlier than 5:59 am (scheduled time), stays at least 3:01 hours in Los Angeles and then arrive at PHL not later than 11pm. Based on the \"scheduled\" times, find which carrier has the highest number of flights with these constraints. \n",
    "# Limit your analysis to February 2007 and use scheduled times.\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as F\n",
    "df1 = df.filter(col('Month').isin([2])) \n",
    "df1 = df1.filter(col('Origin').isin(['PHL', 'LAX'])).filter(col('Dest').isin(['PHL', 'LAX']))\n",
    "df1.show()\n",
    "\n",
    "# df2 = df1.filter(col('DepTime').isin([2])) \n",
    "print('stay 3:0 hour, it means before we shoulf flight here at least before back-fight start time - 3hours')\n",
    "dates = (\"1970-01-01 5:59:00\", \"1970-01-01 20:00:00\", \"1970-01-01 23:00:00\")\n",
    "# date_from, date_to = [to_date(lit(s)).cast(TimestampType()) for s in dates]\n",
    "\n",
    "\n",
    "df2 = df1.withColumn('DepTime_Date', F.to_timestamp('DepTime', 'hhmm'))\n",
    "df3 = df2.withColumn('ArrTime_Date', F.to_timestamp('ArrTime', 'hhmm'))\n",
    "# df2.show()\n",
    "\n",
    "df4 = df3.where( ((col('DepTime_Date') > dates[0]) & (col('ArrTime_Date') < dates[1])) |\n",
    "           (col('ArrTime_Date') < dates[2])\n",
    "         ).show(truncate=False)\n",
    "\n",
    "if df4 is not None:\n",
    "    df5 = df4.groupBy('UniqueCarrier').count()\n",
    "    k_v = {}\n",
    "    for orgin in df5.collect():\n",
    "\n",
    "        k_v[orgin['UniqueCarrier']] = orgin['count']\n",
    "    print(k_v)\n",
    "    if k_v is None:\n",
    "        carriar_max = max(k_v.items(), key=operator.itemgetter(1))[0]\n",
    "        print('max UniqueCarrier :', carriar_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- departure flights ----------\n",
      "1340 1232 2891 ONT\n",
      "1410 1251 933 SAN\n",
      "1205 1042 1554 SAN\n",
      "1225 1045 1502 SEA\n",
      "1300 1140 1596 SNA\n",
      "1300 1233 851 LAS\n",
      "1155 1035 1184 OAK\n",
      "1315 1101 324 PHX\n",
      "1450 1245 1684 PHX\n",
      "1250 1136 2037 SJC\n",
      "1220 1052 1977 SMF\n",
      "1340 1215 2588 SMF\n",
      "1225 959 1477 CLE\n",
      "1225 1058 2108 DAL\n",
      "1115 1014 1361 LIT\n"
     ]
    }
   ],
   "source": [
    "## Q9\n",
    "#Generate the `departure flights` board of the Los Angeles Airport at 12 Jan 2007 at 13:00. \n",
    "# The board should contain flights with actual departure times between 12:00 and 14:00, \n",
    "# sorted by scheduled departure time. The resulting table should at least contain scheduled departure time, \n",
    "# actual departure time (if departed), \n",
    "# airline code, and destination\n",
    "df1 = df.filter(col('Month').isin([1])).filter(col('DayofMonth').isin([1]))\n",
    "\n",
    "dates = (\"1970-01-01 12:00:00\", \"1970-01-01 14:00:00\")\n",
    "dates = (\"1970-01-01 00:01:00\", \"1970-01-01 23:59:00\")\n",
    "# date_from, date_to = [to_date(lit(s)).cast(TimestampType()) for s in dates]\n",
    "\n",
    "df1 = df1.withColumn(\n",
    "    \"CRSDepTime\",\n",
    "    F.when(F.col(\"CRSDepTime\").isNull(), '0')\n",
    "    .otherwise(F.col(\"CRSDepTime\").cast(\"string\"))\n",
    ")\n",
    "df2 = df1.withColumn('DepTime_Date', F.to_timestamp('CRSDepTime', 'hhmm'))\n",
    "\n",
    "# df2.show()\n",
    "# print('@'*20)\n",
    "\n",
    "df4 = df2.where( \n",
    "    ((col('DepTime_Date') > dates[0]) & (col('DepTime_Date') < dates[1]))\n",
    "         )\n",
    "\n",
    "print('-'*10, 'departure flights', '-'*10)\n",
    "for item in df4.rdd.collect():\n",
    "#     print(item)\n",
    "    print(item['CRSArrTime'],item['DepTime'], item['FlightNum'], item['Dest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
