# 创新点
1.数据清洗和准备
在数据清洗和准备的部分，通过使用Spark DataFrame中的函数，
例如dropna()函数，将包含缺失值的数据行删除，从而清除了原始数据中的噪声，并减少了在后续分析中的误差。

2.特征工程
在特征工程部分，通过使用VectorAssembler将年份、月份和日份这三个特征组合成一个特征向量，
并将其用于训练机器学习模型。

3.使用Spark进行机器学习建模
在使用Spark进行机器学习建模的部分，使用了Spark中的线性回归、随机森林和梯度提升树3种回归模型进行训练和预测，以
及使用了Spark中的评估器进行模型评估，例如RegressionEvaluator。一般论文只使用了1-2种
这里主要创新点是：
梯度提升树(Gradient Boosting Tree, GBT)是一种集成学习方法，它结合了多个决策树模型以提高预测准确性。G
BT模型是一个迭代模型，每一次迭代都会构建一个新的决策树模型，该模型会针对先前模型预测错误的数据点进行优化。这种集成学习方法有以下创新点：

迭代优化：GBT采用迭代优化的方法，通过逐步优化每一次迭代的模型，最终得到一个强大的模型。
每一次迭代会针对先前模型预测错误的数据点进行优化，从而更加准确地预测这些点的值。

集成学习：GBT模型结合了多个决策树模型以提高预测准确性。集成学习是一种将多个弱分类器组合成一个强分类器的方法，
它可以在不同方面提高模型的性能，例如减少过拟合和提高准确性等。

灵活性：GBT模型非常灵活，可以应用于不同类型的数据集和问题。
它可以应用于回归和分类问题，也可以处理连续和离散变量。

可解释性：GBT模型可以提供对特征重要性的解释，这有助于我们了解哪些特征对预测结果的影响最大。
这种可解释性对于许多应用程序来说非常重要，例如金融预测和医疗诊断。

可扩展性：GBT模型可以应用于大规模数据集，可以使用并行计算和分布式计算等技术来加速模型训练和预测。
这使得GBT模型在处理大型数据集时非常有用，例如电子商务和社交媒体等领域。


4.可视化
在可视化部分，做了很多很多：
通过使用Matplotlib库中的函数，例如plot()函数和scatter()函数，
将预测结果可视化，以帮助更好地理解模型的表现。



# 代码主体结构：
部分1：创建SparkSession和导入数据
首先，我们需要创建一个SparkSession，以便使用Spark SQL和机器学习库。
然后，我们使用spark.read.format()方法从CSV文件中加载数据。在加载数据之后，
我们将数据中的demand列转换为double类型，以便进行数学计算。接下来，我们对数据进行一些清洗和准备工作，
例如删除缺失值，将时间戳列转换为datetime类型，以及添加年份、月份和日期列。

部分2：特征工程和训练模型
在这个部分，我们使用VectorAssembler将特征列（年份、月份和日期）组合成一个向量列。
然后，我们使用randomSplit方法将数据集拆分为训练集和测试集。
接下来，我们定义线性回归模型，并使用训练集拟合该模型。最后，我们使用测试集对模型进行评估，并展示预测结果。

第3部分：训练模型并进行预测

在前两部分中，我们对数据进行了清洗和准备，并对其进行了特征工程。现在，我们可以训练我们的模型并进行预测。

3.1 线性回归模型

我们首先使用线性回归模型进行预测。
主要讲了如何使用Spark ML库训练一个线性回归模型，使用测试数据进行预测并显示预测结果

3.2 随机森林回归模型

接下来，我们使用随机森林回归模型进行预测。
主要讲了如何使用Spark ML库训练一个随机森林回归模型，使用测试数据进行预测并计算均方误差。

3.3 梯度提升树回归模型

最后，我们使用梯度提升树回归模型进行预测。
主要讲了如何使用Spark ML库训练一个梯度提升树回归模型，使用测试数据进行预测并计算均方误差

