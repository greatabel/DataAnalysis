{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed05da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55315f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 22:21:29 WARN Utils: Your hostname, AbeldeMacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.102 instead (on interface en0)\n",
      "23/04/18 22:21:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/18 22:21:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# 创建SparkSession\n",
    "spark = SparkSession.builder.appName('Demand Prediction').getOrCreate()\n",
    "\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac4b08af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Path does not exist: file:/Users/abel/AbelProject/DataAnalysis/university_counselor/b25437_demand_forecast_pyspark/data/Aggregate/daily_demand_totals.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 导入数据\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/data_sample.csv\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/Aggregate/daily_demand_totals.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Envs/samaritan0/lib/python3.9/site-packages/pyspark/sql/readwriter.py:177\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n",
      "File \u001b[0;32m~/Envs/samaritan0/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/Envs/samaritan0/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Path does not exist: file:/Users/abel/AbelProject/DataAnalysis/university_counselor/b25437_demand_forecast_pyspark/data/Aggregate/daily_demand_totals.csv"
     ]
    }
   ],
   "source": [
    "# 导入数据\n",
    "# data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/data_sample.csv\")\n",
    "data = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"data/Aggregate/daily_demand_totals.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53704ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'demand' column to a numeric type\n",
    "data = data.withColumn(\"demand\", col(\"demand\").cast(\"double\"))\n",
    "# 数据清洗和准备\n",
    "data = data.dropna()\n",
    "data = data.withColumn(\"timestamp\", to_timestamp(col(\"timestamp\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "data = data.withColumn(\"year\", year(col(\"timestamp\")))\n",
    "data = data.withColumn(\"month\", month(col(\"timestamp\")))\n",
    "data = data.withColumn(\"day\", dayofmonth(col(\"timestamp\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "assembler = VectorAssembler(inputCols=[\"year\", \"month\", \"day\"], outputCol=\"features\")\n",
    "data = assembler.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff19e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 划分训练和测试数据集\n",
    "(train_data, test_data) = data.randomSplit([0.7, 0.3], seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6801182",
   "metadata": {},
   "source": [
    "# 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc578cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制demand的直方图\n",
    "demand = pd.DataFrame(train_data.select('demand').rdd.map(lambda x: x[0]).collect(), columns=['demand'])\n",
    "demand.plot(kind='hist', bins=20)\n",
    "plt.xlabel('Demand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a19fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制demand和时间的散点图\n",
    "data = train_data.select('timestamp', 'demand').toPandas()\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "data.plot(x='timestamp', y='demand', kind='scatter', s=1)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Demand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d653771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用箱线图来检测异常值和数据分布的形状\n",
    "demand = pd.DataFrame(train_data.select('demand').rdd.map(lambda x: x[0]).collect(), columns=['demand'])\n",
    "demand.plot(kind='box')\n",
    "plt.xlabel('Demand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa94ff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义线性回归模型\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"demand\")\n",
    "\n",
    "# 训练模型\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# 预测未来需求\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# 展示预测结果\n",
    "predictions.select(\"year\", \"month\", \"day\", \"demand\", \"prediction\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed854311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建随机森林回归模型\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"demand\", numTrees=10)\n",
    "\n",
    "# 训练模型\n",
    "rf_model = rf.fit(train_data)\n",
    "\n",
    "# 预测未来需求\n",
    "predictions = rf_model.transform(test_data)\n",
    "\n",
    "# 计算模型的评估指标（均方误差）\n",
    "evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "\n",
    "# 展示预测结果\n",
    "predictions.select(\"year\", \"month\", \"day\", \"demand\", \"prediction\").show()\n",
    "\n",
    "# 输出均方误差\n",
    "print(\"Mean Squared Error (MSE) on test data = %g\" % mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f18729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建梯度提升树回归模型\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"demand\", maxIter=10)\n",
    "\n",
    "# 训练模型\n",
    "gbt_model = gbt.fit(train_data)\n",
    "\n",
    "# 预测未来需求\n",
    "predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# 计算模型的评估指标（均方误差）\n",
    "evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(predictions)\n",
    "\n",
    "# 展示预测结果\n",
    "predictions.select(\"year\", \"month\", \"day\", \"demand\", \"prediction\").show()\n",
    "\n",
    "# 输出均方误差\n",
    "print(\" 3 Mean Squared Error (MSE) on test data = %g\" % mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449493a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#'*20)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 使用三种不同的模型进行预测\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "gbt_predictions = gbt_model.transform(test_data)\n",
    "\n",
    "# 使用均方误差评估每个模型的预测效果\n",
    "lr_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "lr_mse = lr_evaluator.evaluate(lr_predictions)\n",
    "rf_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "rf_mse = rf_evaluator.evaluate(rf_predictions)\n",
    "gbt_evaluator = RegressionEvaluator(labelCol=\"demand\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "gbt_mse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8021ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选取 lr_model作为例子 预测误差分布图来观察模型的预测误差是否符合正态分布\n",
    "# 计算预测误差\n",
    "lr_predictions = lr_model.transform(test_data)\n",
    "lr_errors = lr_predictions.select(\"demand\", \"prediction\").rdd.map(lambda x: x[0] - x[1]).collect()\n",
    "\n",
    "# 绘制预测误差分布图\n",
    "pd.DataFrame(lr_errors, columns=['error']).plot(kind='hist', bins=20)\n",
    "plt.xlabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac116e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个时间序列的数组\n",
    "time_series = test_data.select(\"timestamp\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Create a matplotlib chart and plot the actual demand and predictions from each model\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(time_series, test_data.select(\"demand\").collect(), label=\"Actual\")\n",
    "ax.plot(time_series, rf_predictions.select(\"prediction\").collect(), label=\"RF Prediction\")\n",
    "ax.plot(time_series, gbt_predictions.select(\"prediction\").collect(), label=\"GBT Prediction\")\n",
    "ax.scatter(time_series, lr_predictions.select(\"prediction\").collect(), label=\"LR Prediction\")\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Demand\")\n",
    "ax.set_title(\"Comparison of Demand Prediction Models\")\n",
    "ax.legend()\n",
    "\n",
    "# Show the chart\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 输出评估结果\n",
    "print(\"Linear Regression Mean Squared Error (MSE) on test data = %g\" % lr_mse)\n",
    "print(\"Random Forest Mean Squared Error (MSE) on test data = %g\" % rf_mse)\n",
    "print(\"Gradient Boosting Tree Mean Squared Error (MSE) on test data = %g\" % gbt_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2f561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('在预测结果可视化图表中，随机森林(Random Forest)模型和梯度提升树(Gradient Boosting Tree)模型的预测结果比线性回归(Linear Regression)模型的预测结果更接近实际需求值')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f01b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e2b630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9aa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
