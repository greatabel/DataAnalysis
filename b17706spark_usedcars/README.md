1.
安装python3.6 以上版本

2. 
安装pip3 

3.
可选  可以不做（创建python3虚拟目录，隔绝不同版本库之间相互影响）
https://docs.python.org/zh-cn/3/tutorial/venv.html

4.
4.1
terminal底下进入工程目录下，在requirements.txt同级目录下运行：
pip install --upgrade -r requirements.txt

5.
模拟运行在:
命令行底下运行: 
python3 i6wsgi.py


开启另一个命令行运行，运行：
jupyter notebook i5ml_spark_anlysis.ipynb

可以运行可视化部分、查看分析结果部分，推荐系统部分



6.
浏览器访问：

http://localhost:5000/home

默认账号 greatabel1@126.com ps:abel
自己也可以正常注册


--------------------
工程说明部分：

数据集主要是用ebay的数据集，二手车数据集 ebay开源出来的，主要分析的是美国二手车市场的数据分析。

数据目前是晚上我临时搞的以前的，不是全部的spark上跑的数据。这个周六会更新。

可视化和分析部分主要用到啦这些python库：
NumPy 
	NumPy 是使用 Python 进行科学计算的基础软件包。它可用来存储和处理大型矩阵，比使用 Python 本身处理要高效的多，支持高维度数组与矩阵的运算，此外也针对数组提供了大量的数学函数库
Pandas
	为Python 编程语言提供高性能，易于使用的数据结构和数据分析工具，和numpy打配合的
Matplotlib和Seaborn
	Seaborn是用户把自己常用到的可视化绘图过程进行了函数封装，形成的一个“快捷方式”，他相比Matplotlib的好处是代码更简洁，可以用一行代码实现一个清晰好看的可视化输出。主要的缺点则是定制化能力会比较差，只能实现固化的一些可视化模板类型；而Matplotlib是可以实现高度定制化绘图的，高度定制化可以让你获得最符合心意的可视化输出结果，但也因此需要设置更多的参数，因而代码更加复杂一些

我们的展示整个结果的网站是flask，前端部分是jinja+vue+echart+js

我们的推荐引擎部分（还没有演示，是给予协同推荐）python3 + numpy + pandas实现
	协同过滤的模型一般为m个物品，m个用户的数据，只有部分用户和部分数据之间是有评分数据的，其它部分评分是空白，此时我们要用已有的部分稀疏数据来预测那些空白的物品和数据之间的评分关系，找到最高评分的物品推荐给用户。
	我们根据已经有的ebay数据集，我们专门针对造的用户挑选一批精选数据，做协同推荐，因为数据集是车的，没有其他用户登录网站交互，只能自己挑选车信息，然后根据这些，制造一部分目标用户和 挑选出来做推荐的背景交互数据）。


（可选部分）：
同时在约定之外，我们为啦数据好看（比如为啦获取电动车和汽油车之间的可视化），同时我用python3 + scrapy框架也下载啦一部分爬虫数据（评价和社交网络的tweets/quora数据，做数据可视化部分）。Scrapy是用纯Python实现一个为了爬取网站数据、提取结构性数据而编写的应用框架，用途非常广泛。框架的力量，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常之方便。我们用到啦
scrapy和selenium。
Selenium的核心Selenium Core基于JsUnit，完全由JavaScript编写，因此可以用于任何支持JavaScript的浏览器上。
selenium可以模拟真实浏览器，自动化测试工具，支持多种浏览器，爬虫中主要用来解决JavaScript渲染问题。现在一般是用selenium逃过网站监测，比如quora我就是用selenium抓取的

